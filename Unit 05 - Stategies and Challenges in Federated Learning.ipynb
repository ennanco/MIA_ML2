{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec90de6c",
   "metadata": {},
   "source": [
    "# Revisiting the Strategies in Federated Learning\n",
    "\n",
    "As mentioned in the previous unit, Strategies are at the core of federated learning. They determine how clients are selected, which updates are used, and how the new changes are aggregated.\n",
    "\n",
    "In this unit, we will focus on custom Strategies. To begin, we need to set up the environment for this notebook's development.\n",
    "\n",
    "### Exercise\n",
    "As you are familiar with one of the deep learning frameworks, you can implement the following part based on your preference, either PyTorch, Tensorflow, or JAX.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5d8daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from typing import List, Dict, Optional, Tuple, Union\n",
    "\n",
    "import flwr as fl\n",
    "\n",
    "\n",
    "#Load the CIFAR-10 in NUM_CLIENTS different subsets for the training and test as it has been in the previous unit\n",
    "import numpy as np\n",
    "\n",
    "NUM_CLIENTS = 10\n",
    "\n",
    "\n",
    "# Code to load the dataset\n",
    "def load_datasets(num_clients: int):\n",
    "    # Distribute it to train and test set\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    # Normalize data\n",
    "    x_train = x_train.astype(\"float32\") / 255.0\n",
    "    x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "    x_train, y_train = x_train[:10_000], y_train[:10_000]\n",
    "    x_test, y_test = x_test[:1000], y_test[:1000]\n",
    "\n",
    "    # Randomize the datasets\n",
    "    #TODO\n",
    "\n",
    "    # Split training set into 'num_clients' partitions to simulate the individual dataset\n",
    "    #TODO\n",
    "\n",
    "    # Split each partition\n",
    "    #TODO\n",
    "    \n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "\n",
    "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)\n",
    "\n",
    "# Define the model to be used in the clients\n",
    "\n",
    "# The part to adjust for each framework\n",
    "def generate_ann():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_parameters(net) -> List[np.array]:\n",
    "    return net.get_weights()\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    #TODO\n",
    "    return net\n",
    "\n",
    "\n",
    "def train(net, trainloader, epochs: int):\n",
    "    #TODO\n",
    "    return net\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    #TODO\n",
    "    return loss, accuracy\n",
    "\n",
    "# Class to contain a Client\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    #TODO\n",
    "\n",
    "def client_fn(Context) -> Client:\n",
    "    #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf38ccc",
   "metadata": {},
   "source": [
    "Considering the previous code, the model developed has several possibilities for implementing the Strategy object such as `FedAvg` or `FedAdagrad`,  as seen in the  previous Unit. For example, the following code should create a strategy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7372f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the model and get the parameters\n",
    "model = generate_ann()\n",
    "params = get_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae7b13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.server import ServerApp, ServerAppComponents\n",
    "\n",
    "num_rounds = 3\n",
    "\n",
    "def server_fn(context: Context):\n",
    "    #TODO...\n",
    "\n",
    "\n",
    "    # Create FedAvg strategy\n",
    "    strategy = fl.server.strategy.FedAvg(\n",
    "            fraction_fit=0.3,  \n",
    "            fraction_evaluate=0.3,  \n",
    "            min_fit_clients=3,\n",
    "            min_evaluate_clients=2,\n",
    "            min_available_clients=NUM_CLIENTS, \n",
    "            initial_parameters=fl.common.ndarrays_to_parameters(params), # Initial parameters\n",
    "    )\n",
    "\n",
    "    # Define ServerConfig\n",
    "    #TODO\n",
    "\n",
    "    # Return the configuration and strategy for this server\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "# Create Server\n",
    "server_app = ServerApp(server_fn=server_fn)\n",
    "\n",
    "    #Start the simulation\n",
    "fl.simulation.run_simulation(\n",
    "    server_app=server_app, client_app=client_app, num_supernodes=NUM_CLIENTS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631b8323",
   "metadata": {},
   "source": [
    "It may be worth mentioning that Flower, by default, initializes the global model by making a call to one random client before distributing it to the remaining clients. However, sometimes more control is required, such as when performing fine-tuning. In such situations, we use server-side initialization, and the `initial_parameters` parameter will hold the initial version of the model for all clients. It is important to note that this parameter must be a serialization of the data, so the utility function `ndarrays_to_parameters` can be quite handy in this case.\n",
    "\n",
    "Now, let's move on to customizing the type of evaluation performed on the models. Broadly speaking, there are two possibilities: server-side evaluation and client-side evaluation.\n",
    "\n",
    "**Centralized evaluation** (server-side) is similar to traditional machine learning, where the server holds a partition solely for evaluating the aggregated model. This approach reduces communication and is suitable for situations with limited bandwidth. There is no need to send the model to the clients for evaluation, and the entire evaluation dataset is available at all times.\n",
    "\n",
    "**Federated evaluation** (client-side) is more complex, but it usually represents real-world scenarios more accurately. In this approach, the evaluation dataset is distributed among the clients, which means that we can leverage a larger dataset spread among the resources of the clients. However, this approach comes with a cost. Since we don't have a central dataset, we should be aware that our evaluation dataset can change over consecutive rounds of learning if some clients are not always available. Moreover, the dataset held by each client can also change over consecutive rounds. This can lead to evaluation results that are not stable, so even if we don't change the model, we can see our evaluation results fluctuate over consecutive rounds. Additionally, this approach can significantly increase the number of communications because the models have to be distributed among the clients and retrieved for evaluation.\n",
    "\n",
    "The previous code snippet is an example of Flower performing Federated evaluations, as it uses the `evaluation` function that is executed on each `Client` and later aggregated after being sent to the server. On the other hand, a Centralized evaluation could be performed with a similar approach, as shown in the following code snippet:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788a1b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluate_fn(input_dataset):\n",
    "# The `evaluate` function will be by Flower called after every round\n",
    "    def evaluate_fn(\n",
    "        server_round: int, parameters: fl.common.NDArrays, \n",
    "        config: Dict[str, fl.common.Scalar]) -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
    "        #Load the test data\n",
    "        dataset = input_dataset\n",
    "        \n",
    "        # Update the model with the latest parameters\n",
    "        set_parameters(model, parameters)\n",
    "    \n",
    "        # Evaluate the model on the test dataset\n",
    "        loss, accuracy = test(model, dataset)\n",
    "    \n",
    "        # Log the evaluation results\n",
    "        print(f\"Server-side evaluation round {server_round} with loss {loss} / accuracy {accuracy}\")\n",
    "        \n",
    "        return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "    return evaluate_fn\n",
    "\n",
    "def server_fn(context: Context):\n",
    "    #TODO ... \n",
    "\n",
    "\n",
    "    # Create FedAvg strategy\n",
    "    strategy = fl.server.strategy.FedAvg(\n",
    "            fraction_fit=0.3,  \n",
    "            fraction_evaluate=0.3,  \n",
    "            min_fit_clients=3,\n",
    "            min_evaluate_clients=2,\n",
    "            min_available_clients=NUM_CLIENTS, \n",
    "            initial_parameters=fl.common.ndarrays_to_parameters(params),\n",
    "            evaluate_fn=get_evaluate_fn(testloader[0]),  # Pass the evaluation function\n",
    "    )\n",
    "\n",
    "    # Define ServerConfig\n",
    "    #TODO ...\n",
    "\n",
    "    # Return the configuration and strategy for this server\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "# Create Server\n",
    "server_app = ServerApp(server_fn=server_fn)\n",
    "\n",
    "#Start the simulation\n",
    "fl.simulation.run_simulation(\n",
    "    server_app=server_app, client_app=client_app, num_supernodes=NUM_CLIENTS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ffb7e9",
   "metadata": {},
   "source": [
    "Additionally, it is possible to implement a custom strategy from scratch by implementing the necessary methods and extending `flwr.server.strategy.Strategy`. The required methods for a custom strategy are as follows:\n",
    "* `num_fit_clients`: returns the number of clients to be selected for the next round of training.\n",
    "* `num_rounds`: returns the number of rounds of training to perform.\n",
    "* `on_fit`: called when a client has completed training and returned its updated model. This method should update the global model based on the returned model.\n",
    "* `on_evaluate`: called when a client has completed an evaluation and returned its evaluation result. This method should aggregate the evaluation results.\n",
    "\n",
    "\n",
    "You can see an schema of the methods and an example in the following [link](https://flower.ai/docs/framework/tutorial-series-build-a-strategy-from-scratch-pytorch.html#Build-a-Strategy-from-scratch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585a7905",
   "metadata": {},
   "source": [
    "# Challenges for Federated Learning\n",
    "\n",
    "While federated learning can solve problems that traditional centralized machine learning struggles with, such as privacy and reduced hardware requirements, it also presents its own challenges. In this section, we will cover some of these challenges, including the non-IID (independent and identically distributed) nature of the data, the heterogeneous nature of devices, and the limited communication bandwidth.\n",
    "\n",
    "## Non-IID data\n",
    "The assumption of independence and identical distribution, or i.i.d., is commonly made in machine learning and statistical analysis. This means that each data point is independent of all other data points, and that the distribution of the data is the same across all data points.\n",
    "\n",
    "Non-i.i.d. data, on the other hand, violates one or both of these assumptions. This can occur for a variety of reasons. For example, data may be collected in a way that introduces dependencies between data points, such as when data is collected over time or in a specific order. Additionally, the distribution of the data may vary across different subgroups or regions, making it non-i.i.d. Non-i.i.d. data is a common challenge in federated learning because the data is distributed across many devices, and each device may have a different distribution of data due to variations in data collection methods or data sources. As a result, traditional machine learning algorithms may not perform well on non-i.i.d. data.\n",
    "\n",
    "In a non-IID data problem (see Figure 1(a)), \"non-IIDness\" (see Figure 1(c)) refers to the presence of couplings (such as co-occurrence, neighborhood, dependency, linkage, correlation, and causality) and heterogeneities within and between two or more aspects, such as entities, entity classes, entity properties (variables), processes, facts, and states of affairs, or other types of entities or properties (such as learners and learned results) that appear or are produced prior to, during, and after a target process (such as a learning task). Conversely, IIDness ignores or simplifies these relationships, as shown in Figure 1(b).\n",
    "\n",
    "![Diagram with IID and non-IID data](https://datasciences.org/wp-content/themes/dslabNew/images/datasciences/IIDness.png)\n",
    "Credit: [Source of the image](https://datasciences.org/non-iid-learning/)\n",
    "\n",
    "Non-i.i.d. data can be more challenging to work with than i.i.d. data because standard statistical assumptions and techniques may not be applicable. Therefore, special techniques may need to be employed to analyze non-i.i.d. data, which may include techniques that take into account the dependencies between data points or the varying data distributions.\n",
    "\n",
    "In this context, non-i.i.d. data refers to the fact that the data on each device may differ in terms of distribution, characteristics, and relevance to the task at hand. For instance, the data on one device may comprise mainly images of dogs, while the data on another device may consist mainly of images of cats. This can pose a challenge in training a model that performs well on all the devices because the data on each device can vary significantly from the data on the other devices.\n",
    "\n",
    "To address non-i.i.d. data in federated learning, special techniques are often employed to weigh the contributions of each device's data to the overall model, or to adjust the model's parameters in a way that considers the differences in the data. Furthermore, techniques such as data augmentation and transfer learning could help to generalize the model beyond the device's data.\n",
    "\n",
    "When discussing Flower, the approach to addressing this problem would involve [implementing](https://flower.ai/docs/framework/how-to-implement-strategies.html) a custom strategy, similar to the following example, that uses a custom aggregation of the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf098de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.common import EvaluateRes, FitRes, Scalar\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "\n",
    "class AggregateCustomMetricStrategy(fl.server.strategy.FedAvg):\n",
    "    #aggregate_evaluate is responsible for aggregating the results \n",
    "    #returned by the clients that were selected and asked to evaluate in configure_evaluate.\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation accuracy using weighted average.\"\"\"\n",
    "\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        # Call aggregate_evaluate from base class (FedAvg) to aggregate loss and metrics\n",
    "        aggregated_loss, aggregated_metrics = super().aggregate_evaluate(server_round, results, failures)\n",
    "\n",
    "        # Weigh accuracy of each client by number of examples used\n",
    "        accuracies = [r.metrics[\"accuracy\"] * r.num_examples for _, r in results]\n",
    "        examples = [r.num_examples for _, r in results]\n",
    "\n",
    "        # Aggregate and print custom metric\n",
    "        aggregated_accuracy = sum(accuracies) / sum(examples)\n",
    "        print(f\"Round {server_round} accuracy aggregated from client results: {aggregated_accuracy}\")\n",
    "\n",
    "        # Return aggregated loss and metrics (i.e., aggregated accuracy)\n",
    "        return aggregated_loss, {\"accuracy\": aggregated_accuracy}\n",
    "\n",
    "\n",
    "def server_fn(context: Context):\n",
    "    # instantiate the model\n",
    "    #TODO\n",
    "\n",
    "    # Create strategy and run server\n",
    "    strategy = AggregateCustomMetricStrategy(\n",
    "    #TODO\n",
    "    )\n",
    "    \n",
    "    # Define ServerConfig\n",
    "    #TODO ...\n",
    "\n",
    "    # Wrap everything into a `ServerAppComponents` object\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "\n",
    "# Create your ServerApp\n",
    "server_app = ServerApp(server_fn=server_fn)\n",
    "\n",
    "#Start the simulation\n",
    "fl.simulation.run_simulation(\n",
    "    server_app=server_app, client_app=client_app, num_supernodes=NUM_CLIENTS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a017a00",
   "metadata": {},
   "source": [
    "## Heterogeneity of the devices\n",
    "\n",
    "The heterogeneity of the devices in the network, which means they may have different hardware and software configurations and may be running different versions of the operating system, is one of the problems of federated learning. This can lead to several problems, including:\n",
    "\n",
    "* Inefficient communication: Different devices may have varying network speeds and bandwidth, which can make it difficult to transmit model updates between devices in a timely manner.\n",
    "\n",
    "* Incompatible updates: If different devices are running different versions of the operating systems, they may not be able to exchange model updates due to compatibility issues.\n",
    "\n",
    "* Data heterogeneity: The data on different devices may differ in terms of quality, quantity, and format, making it challenging to train a model that generalizes well across all devices.\n",
    "\n",
    "\n",
    "\n",
    "To mitigate the impact of heterogeneous devices in federated learning, researchers are developing techniques such as device-aware aggregation algorithms and communication optimization. These techniques aim to address issues such as inefficient communication and incompatible updates resulting from differences in network speeds, bandwidth, operating system versions, and data heterogeneity across the devices.\n",
    "\n",
    "\n",
    "Consider a network of five devices (A, B, C, D, and E) that are participating in federated learning to train a global model. Each device has its own data and trains a local model on that data. The local models are then transmitted back to a central server, where they are aggregated and used to update the global model.\n",
    "\n",
    "\n",
    "In the above scenario, the participating devices (A, B, C, D, and E) in the federated learning network are heterogeneous in nature, meaning they possess different hardware and software configurations. For instance, Device A and Device B may be running distinct versions of the operating system, and Device C may have a slower network connection in comparison to the other devices.\n",
    "\n",
    "\n",
    "This heterogeneity in the devices can create challenges in the federated learning process. For instance, Device A may face difficulty sending its local model update to the server because of compatibility issues with Device B, and Device C may experience a slower transmission due to its slower network connection.\n",
    "\n",
    "\n",
    "To overcome the challenges posed by heterogeneous devices in federated learning, researchers are developing techniques to mitigate their impact. These techniques may include device-aware aggregation algorithms, which take into account the different hardware and software configurations of the devices, and communication optimization techniques such as data compression and intelligent routing. By adapting the way that data is aggregated and transmitted, these techniques can help to ensure that all devices are able to contribute effectively to the global model, regardless of their individual characteristics.\n",
    "\n",
    "\n",
    "\n",
    "It is also worth mentioning that a local configuration can be provided to the `Clients` by means of the `config` parameter of the function in the `FlowerClient`. This parameter is a Python `Dict` which holds values that can be used internally for different purposes, such as limiting the number of epochs on certain clients or establishing the number of rounds.\n",
    "\n",
    "\n",
    "The modification for the strategy in this case would require the use of parameter `on_fit_config` to indicate the function to retrieve the correct configuration.\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "...\n",
    "\n",
    "def fit_config(server_round: int):\n",
    "    \"\"\"Return training configuration dict for each round.\n",
    "\n",
    "    Perform two rounds of training with one local epoch, increase to two local\n",
    "    epochs afterwards.\n",
    "    \"\"\"\n",
    "    config = {\n",
    "        \"server_round\": server_round,  # The current round of federated learning\n",
    "        \"local_epochs\": 1 if server_round < 2 else 2,\n",
    "    }\n",
    "    return config\n",
    "\n",
    "...\n",
    "\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=0.3,\n",
    "    fraction_evaluate=0.3,\n",
    "    min_fit_clients=3,\n",
    "    min_evaluate_clients=3,\n",
    "    min_available_clients=10,\n",
    "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(model)),\n",
    "    evaluate_fn=evaluate,\n",
    "    on_fit_config_fn=fit_config,  # Pass the fit_config function\n",
    ")\n",
    "\n",
    "...\n",
    "```\n",
    "\n",
    "However, sometimes limiting the number of rounds or the number of epochs for each client is not enough, especially when the number of clients is too large to handle. In such cases, it may be necessary to reduce the number of clients used for training and evaluation. For instance, consider a scenario where there are 1000 clients, each with only 50 samples for training and 10 for evaluation. Although the amount of data in each client is limited, the communication overhead can still be overwhelming. In such cases, it is better to train for a longer time with a smaller number of clients in each round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fd3f0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 1000\n",
    "\n",
    "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)\n",
    "\n",
    "def fit_config(server_round: int):\n",
    "    config = {\n",
    "        \"server_round\": server_round,\n",
    "        \"local_epochs\": 3,\n",
    "    }\n",
    "    return config\n",
    "\n",
    "def server_fn(context: Context):\n",
    "    # instantiate the model\n",
    "    #TODO\n",
    "\n",
    "    # Create strategy and run server\n",
    "    strategy = fl.server.strategy.FedAvg(\n",
    "        fraction_fit=0.025,  # Train on 25 clients (each round)\n",
    "        fraction_evaluate=0.05,  # Evaluate on 50 clients (each round)\n",
    "        min_fit_clients=20,\n",
    "        min_evaluate_clients=40,\n",
    "        min_available_clients=NUM_CLIENTS,\n",
    "        initial_parameters=fl.common.ndarrays_to_parameters(params),\n",
    "        on_fit_config_fn=fit_config\n",
    "    )\n",
    "   \n",
    "    # Define ServerConfig\n",
    "    #TODO ...\n",
    "\n",
    "    # Wrap everything into a `ServerAppComponents` object\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "# Create your ServerApp\n",
    "server_app = ServerApp(server_fn=server_fn)\n",
    "\n",
    "#Start the simulation\n",
    "fl.simulation.run_simulation(\n",
    "    server_app=server_app, client_app=client_app, num_supernodes=NUM_CLIENTS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85f1abb",
   "metadata": {},
   "source": [
    "In addition to the techniques mentioned earlier, federated transfer learning, secure aggregation, and data augmentation are other approaches that can help in the scaling of the federated learning system. The limitation of resources, including bandwidth, storage, and computation power, is one of the main challenges of federated learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb36a82b",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "As evident from the previous results, the outcomes are not remarkable, mainly attributed to the limited number of patterns for each client. In response, suggest an alternative architecture for the network and experiment with at least four different configurations for the fraction_fit and evaluate. Subsequently, analyze the data and draw conclusions from your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e97ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
